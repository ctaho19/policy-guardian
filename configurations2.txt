def load_thresholds(spark: SparkSession) -> pd.DataFrame:
    threshold_query = """
    SELECT 
        MONITORING_METRIC_ID,
        ALERT_THRESHOLD,
        WARNING_THRESHOLD
    FROM CYBR_DB_COLLAB.LAB_ESRA_TCRD.CYBER_CONTROLS_MONITORING_THRESHOLD
    WHERE MONITORING_METRIC_ID IN ('MNTR-XXXXXX-T1', 'MNTR-XXXXXX-T2')
    """
    logger.info("Loading Tier 1 and Tier 2 thresholds from Snowflake")
    thresholds_df = spark.read.format(SNOWFLAKE_SOURCE_NAME) \
        .options(**sfOptions) \
        .option("query", threshold_query) \
        .load()
    
    threshold_data = thresholds_df.collect()
    logger.info(f"Threshold data collected: {threshold_data}, type: {type(threshold_data)}")
    
    if threshold_data:
        data = [
            {
                "MONITORING_METRIC_ID": row["MONITORING_METRIC_ID"],
                "ALERT_THRESHOLD": row["ALERT_THRESHOLD"],
                "WARNING_THRESHOLD": row["WARNING_THRESHOLD"]
            } for row in threshold_data
        ]
        return pd.DataFrame(data)
    else:
        logger.warning("No threshold data found; using fallback values")
        return pd.DataFrame([
            {"MONITORING_METRIC_ID": "MNTR-XXXXXX-T1", "ALERT_THRESHOLD": 0.1, "WARNING_THRESHOLD": 0.3},
            {"MONITORING_METRIC_ID": "MNTR-XXXXXX-T2", "ALERT_THRESHOLD": 0.1, "WARNING_THRESHOLD": 0.3}
        ])
​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​

def main():
    # Initialize Spark session
    spark = SparkSession.builder.appName("CyberControlsMonitoring").getOrCreate()

    # Define payloads
    summary_payload = {
        "searchParameters": {
            "resourceType": "AWS::ACM::Certificate",
            "configurationItems": [{"configurationName": "issuer", "configurationValue": "Amazon"}],
            "aggregations": ["resourceType"]
        }
    }

    config_payload = {
        "searchParameters": [{"resourceType": "AWS::ACM::Certificate"}]
    }

    # Configuration to evaluate
    CONFIG_KEY = "issuer"
    CONFIG_VALUE = "Amazon"
    DESIRED_FIELDS = ["accountResourceId", "configuration.issuer", "resourceType"]

    # Step 1: Get summary count
    summary_count = get_summary_count(summary_payload)
    if summary_count is None:
        logger.error("Failed to get summary count. Exiting.")
        return

    # Step 2: Fetch all resources
    all_resources, config_total_count = fetch_all_resources(config_payload)

    # Step 3: Tier 1 - Check if field exists
    tier1_numerator, tier1_non_compliant_df = filter_tier1_resources(all_resources, CONFIG_KEY, DESIRED_FIELDS)
    logger.info(f"Tier 1 Non-compliant DataFrame: {len(tier1_non_compliant_df)} rows")
    print("Tier 1 Non-compliant Resources:")
    print(tier1_non_compliant_df)

    # Step 4: Tier 2 - Check if value matches
    tier2_numerator, tier2_non_compliant_df = filter_tier2_resources(all_resources, CONFIG_KEY, CONFIG_VALUE, DESIRED_FIELDS)
    logger.info(f"Tier 2 Non-compliant DataFrame: {len(tier2_non_compliant_df)} rows")
    print("Tier 2 Non-compliant Resources:")
    print(tier2_non_compliant_df)

    # Step 5: Load thresholds and calculate metrics
    thresholds_df = load_thresholds(spark)
    tier1_threshold = thresholds_df[thresholds_df["MONITORING_METRIC_ID"] == "MNTR-XXXXXX-T1"].iloc[0]
    tier2_threshold = thresholds_df[thresholds_df["MONITORING_METRIC_ID"] == "MNTR-XXXXXX-T2"].iloc[0]
    
    # Tier 1 Metric (all resources should have the field)
    tier1_metric = tier1_numerator / config_total_count if config_total_count > 0 else 0
    tier1_status = get_compliance_status(1 - tier1_metric, tier1_threshold["ALERT_THRESHOLD"], tier1_threshold["WARNING_THRESHOLD"])

    # Tier 2 Metric (among those with field, value should match)
    tier2_denominator = tier1_numerator  # Tier 2 denominator is Tier 1 numerator
    tier2_metric = tier2_numerator / tier2_denominator if tier2_denominator > 0 else 0
    tier2_status = get_compliance_status(1 - tier2_metric, tier2_threshold["ALERT_THRESHOLD"], tier2_threshold["WARNING_THRESHOLD"])

    # Step 6: Create monitoring DataFrame
    monitoring_data = [
        {
            "DATE": datetime.now().strftime("%Y-%m-%d"),
            "MONITORING_METRIC_NUMBER": "MNTR-XXXXXX-T1",
            "MONITORING_METRIC": f"{tier1_numerator}/{config_total_count}",
            "COMPLIANCE_STATUS": tier1_status,
            "NUMERATOR": tier1_numerator,
            "DENOMINATOR": config_total_count
        },
        {
            "DATE": datetime.now().strftime("%Y-%m-%d"),
            "MONITORING_METRIC_NUMBER": "MNTR-XXXXXX-T2",
            "MONITORING_METRIC": f"{tier2_numerator}/{tier2_denominator}",
            "COMPLIANCE_STATUS": tier2_status,
            "NUMERATOR": tier2_numerator,
            "DENOMINATOR": tier2_denominator
        }
    ]
    monitoring_df = pd.DataFrame(monitoring_data)
    logger.info(f"Monitoring DataFrame: {monitoring_df.to_dict(orient='records')}")
    print("Monitoring Report:")
    print(monitoring_df)

    # Step 7: Log results
    logger.info(f"Summary View Total Count: {summary_count}")
    logger.info(f"Tier 1 Numerator (Field Present): {tier1_numerator}")
    logger.info(f"Tier 2 Numerator (Value Matches): {tier2_numerator}")
    logger.info(f"Config Total Count: {config_total_count}")
​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​