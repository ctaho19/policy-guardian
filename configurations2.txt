# Define the controls we’re monitoring, including their IDs and metrics
CONTROL_CONFIGS = [
    {
        "cloud_control_id": "CM-2.AWS.12.v02",  # Cloud system’s control ID (used in queries)
        "ctrl_id": "CTRL-1234567",             # Control ID for Snowflake (e.g., maps to monitoring metrics)
        "metric_ids": {                        # Metrics to calculate for this control
            "tier1": "MNTR-1234567-T1",        # Tier 1: Coverage metric
            "tier2": "MNTR-1234567-T2",        # Tier 2: Compliance metric
            "tier3": "MNTR-1234567-T3"         # Tier 3: SLA compliance metric
        },
        "requires_tier3": True                 # This control needs Tier 3 processing
    },
    {
        "cloud_control_id": "CM-3.AWS.1.v03",
        "ctrl_id": "CTRL-1234568",
        "metric_ids": {
            "tier1": "MNTR-1234568-T1",
            "tier2": "MNTR-1234568-T2"
        },
        "requires_tier3": False                # No Tier 3 for this control
    }
    # Note: Replace CTRL-1234567 and CTRL-1234568 with your actual Control IDs (e.g., CTRL-1074653)
]


-----
def validate_configs():
    """Check that our control configurations are correct before we start."""
    for config in CONTROL_CONFIGS:
        control_id = config["cloud_control_id"]  # Cloud control ID (e.g., CM-2.AWS.12.v02)
        ctrl_id = config.get("ctrl_id")  # Control ID for Snowflake (e.g., CTRL-1234567)
        # Ensure ctrl_id exists and looks valid (e.g., CTRL- followed by numbers)
        if not ctrl_id or not re.match(r'^CTRL-\d+$', ctrl_id):
            logger.error(f"Invalid ctrl_id for {control_id}: {ctrl_id}")
            raise ValueError(f"Invalid ctrl_id: {ctrl_id}")
        # Check all tiers (1, 2, and 3 if applicable)
        tiers = ['tier1', 'tier2'] + (['tier3'] if config.get("requires_tier3", False) else [])
        for tier in tiers:
            metric_id = config["metric_ids"].get(tier)
            # Ensure metric ID exists and follows the pattern (e.g., MNTR-XXXXX-T1)
            if not metric_id or not re.match(r'^MNTR-\w+-T\d$', metric_id):
                logger.error(f"Invalid metric ID for {control_id} in {tier}: {metric_id}")
                raise ValueError(f"Invalid metric ID: {metric_id}")
    logger.info("Control configurations validated successfully")

def calculate_metrics(alert_val, warning_val, numerator, denominator):
    """Calculate a percentage and status (GREEN, YELLOW, RED) based on thresholds."""
    alert = float(alert_val) if alert_val is not None else None  # Alert threshold (RED if below this)
    warning = float(warning_val) if warning_val is not None else None  # Warning threshold (YELLOW if below this)
    numerator = float(numerator)  # Number of “successes” (e.g., compliant roles), float for Snowflake
    denominator = float(denominator)  # Total number (e.g., all roles), float for Snowflake
    
    # Calculate percentage (100% if denominator is 0, meaning no items to measure)
    metric = numerator / denominator * 100 if denominator > 0 else 100.0
    metric = round(metric, 2)  # Round to 2 decimal places for readability
    
    status = "GREEN"  # Default to good status
    # Only check thresholds if both alert and warning are provided
    if alert is not None and warning is not None:
        if metric < alert:
            status = "RED"  # Bad if below alert
        elif metric < warning and metric >= alert:
            status = "YELLOW"  # Warning if between alert and warning
    logger.debug(f"Metric calculated: {metric}%, status: {status}, alert={alert}, warning={warning}, num={numerator}, denom={denominator}")
    return {
        "metric": metric,      # The percentage
        "status": status,      # GREEN, YELLOW, or RED
        "numerator": numerator,  # Count of successes
        "denominator": denominator  # Total count
    }
------
def process_tier1(spark, control_config):
    """Calculate Tier 1 metrics (coverage: % of roles evaluated) and evidence."""
    metric_id = control_config["metric_ids"]["tier1"]  # Get the Tier 1 metric ID (e.g., MNTR-1234567-T1)
    logger.info(f"Processing Tier 1 for control {control_config['cloud_control_id']}, metric {metric_id}")

    # Load thresholds (alert and warning levels) for this metric from Snowflake
    tier1_threshold_query = THRESHOLD_QUERY_TEMPLATE.format(metric_id=metric_id)
    threshold_df = spark.read.format(SNOWFLAKE_SOURCE_NAME).options(**sfOptions).option("query", tier1_threshold_query).load()
    threshold_data = threshold_df.first()  # Expect one row with thresholds
    alert = threshold_data["ALERT_THRESHOLD"] if threshold_data else None  # RED if below this
    warning = threshold_data["WARNING_THRESHOLD"] if threshold_data else None  # YELLOW if below this
    logger.debug(f"Tier 1 thresholds: alert={alert}, warning={warning}")

    # Filter roles to only those in approved accounts and of type MACHINE
    df_filtered = spark.sql("""
        SELECT RESOURCE_ID, AMAZON_RESOURCE_NAME, ACCOUNT, BA, ROLE_TYPE
        FROM all_iam_roles
        WHERE ACCOUNT IN (SELECT ACCOUNT FROM approved_accounts)  -- Only approved accounts
          AND ROLE_TYPE = 'MACHINE'  -- Only machine roles
    """)
    total_roles = df_filtered.count()  # Count total machine roles
    logger.debug(f"Total machine roles: {total_roles}")

    # Get roles that have been evaluated for compliance
    evaluated_roles = spark.table("evaluated_roles")
    # Count how many of our filtered roles were evaluated
    evaluated_count = df_filtered.join(
        evaluated_roles, 
        df_filtered.AMAZON_RESOURCE_NAME == evaluated_roles.RESOURCE_NAME, 
        "inner"  # Only keep matches
    ).count()
    logger.debug(f"Evaluated roles: {evaluated_count}")

    # Calculate the coverage metric (% of roles evaluated)
    metrics = calculate_metrics(alert, warning, evaluated_count, total_roles)
    # Create a DataFrame matching Snowflake’s schema
    metrics_df = spark.createDataFrame([(
        date.today(),              # DATE: Today’s date
        control_config["ctrl_id"], # CTRL_ID: Control ID (e.g., CTRL-1234567)
        metric_id,                 # MONITORING_METRIC_NUMBER: Metric ID
        metrics["metric"],         # MONITORING_METRIC: Percentage (float)
        metrics["status"],         # COMPLIANCE_STATUS: GREEN/YELLOW/RED
        metrics["numerator"],      # NUMERATOR: Number evaluated (float)
        metrics["denominator"]     # DENOMINATOR: Total roles (float)
    )], ["DATE", "CTRL_ID", "MONITORING_METRIC_NUMBER", "MONITORING_METRIC", "COMPLIANCE_STATUS", "NUMERATOR", "DENOMINATOR"])
    logger.info(f"Tier 1 metrics: {metrics}")

    # Create evidence showing which roles were evaluated
    evidence_df = df_filtered.join(
        evaluated_roles, 
        df_filtered.AMAZON_RESOURCE_NAME == evaluated_roles.RESOURCE_NAME, 
        "left_outer"  # Include all filtered roles, even if not evaluated
    ).select("RESOURCE_ID", "AMAZON_RESOURCE_NAME", col("COMPLIANCE_STATUS").alias("EVALUATION_STATUS"))
    logger.debug(f"Tier 1 evidence rows: {evidence_df.count()}")

    return metrics_df, evidence_df  # Return both for writing and displaying
-----
def process_tier2(spark, control_config):
    """Calculate Tier 2 metrics (compliance: % of roles compliant) and evidence."""
    metric_id = control_config["metric_ids"]["tier2"]
    logger.info(f"Processing Tier 2 for control {control_config['cloud_control_id']}, metric {metric_id}")

    # Load thresholds for Tier 2
    tier2_threshold_query = THRESHOLD_QUERY_TEMPLATE.format(metric_id=metric_id)
    threshold_df = spark.read.format(SNOWFLAKE_SOURCE_NAME).options(**sfOptions).option("query", tier2_threshold_query).load()
    threshold_data = threshold_df.first()
    alert = threshold_data["ALERT_THRESHOLD"] if threshold_data else None
    warning = threshold_data["WARNING_THRESHOLD"] if threshold_data else None
    logger.debug(f"Tier 2 thresholds: alert={alert}, warning={warning}")

    # Combine all roles with their compliance status
    df_combined = spark.sql("""
        SELECT a.RESOURCE_ID, a.AMAZON_RESOURCE_NAME, a.ACCOUNT, a.BA, a.ROLE_TYPE, e.COMPLIANCE_STATUS
        FROM all_iam_roles a
        LEFT JOIN evaluated_roles e  -- Include all roles, even if not evaluated
        ON a.AMAZON_RESOURCE_NAME = e.RESOURCE_NAME
        WHERE a.ACCOUNT IN (SELECT ACCOUNT FROM approved_accounts)
          AND a.ROLE_TYPE = 'MACHINE'
    """)
    total_roles = df_combined.count()  # Total machine roles
    logger.debug(f"Total roles in Tier 2: {total_roles}")

    # Count roles that are compliant
    compliant_roles = df_combined.filter(col("COMPLIANCE_STATUS").isin(["Compliant", "CompliantControlAllowance"])).count()
    logger.debug(f"Compliant roles: {compliant_roles}")

    # Calculate compliance metric (% compliant)
    metrics = calculate_metrics(alert, warning, compliant_roles, total_roles)
    metrics_df = spark.createDataFrame([(
        date.today(),
        control_config["ctrl_id"],  # Use Control ID
        metric_id,
        metrics["metric"],
        metrics["status"],
        metrics["numerator"],
        metrics["denominator"]
    )], ["DATE", "CTRL_ID", "MONITORING_METRIC_NUMBER", "MONITORING_METRIC", "COMPLIANCE_STATUS", "NUMERATOR", "DENOMINATOR"])
    logger.info(f"Tier 2 metrics: {metrics}")

    # Save combined data for Tier 3 to use
    df_combined.createOrReplaceTempView("evaluated_roles_with_compliance")
    # Evidence includes all roles and their compliance status
    evidence_df = df_combined.select("RESOURCE_ID", "AMAZON_RESOURCE_NAME", "COMPLIANCE_STATUS")
    logger.debug(f"Tier 2 evidence rows: {evidence_df.count()}")

    return metrics_df, evidence_df
----

