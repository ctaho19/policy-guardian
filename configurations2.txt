def get_summary_count(payload: Dict) -> Optional[int]:
    logger.info(f"Summary View payload: {json.dumps(payload, indent=2)}")
    try:
        response = requests.post(SUMMARY_URL, headers=HEADERS, data=json.dumps(payload), verify=False)
        logger.info(f"Status: {response.status_code}")
        logger.debug(f"Response: {response.text}")
        if response.status_code == 200:
            data = response.json()
            count = data.get("level1List", [{}])[0].get("level1ResourceCount", 0)
            logger.info(f"Summary count: {count}")
            return count
        logger.error(f"Failed: {response.status_code} - {response.text}")
        return None
    except Exception as e:
        logger.error(f"Exception: {str(e)}", exc_info=True)
        return None

def fetch_all_resources(payload: Dict, summary_count: Optional[int] = None) -> Tuple[List[Dict], int]:
    all_resources = []
    total_count = 0
    next_record_key = ""

    logger.info(f"Fetching resources with payload: {json.dumps(payload, indent=2)}")
    while True:
        try:
            if next_record_key:
                payload["nextRecordKey"] = next_record_key
                logger.debug(f"Next key: {next_record_key}")

            response = requests.post(CONFIG_URL, headers=HEADERS, data=json.dumps(payload), verify=False)
            logger.info(f"Status: {response.status_code}")
            logger.debug(f"Response: {response.text}")
            if response.status_code == 200:
                data = response.json()
                resources = data.get("resourceConfigurations", [])
                # Filter to keys with non-empty origin
                filtered_resources = [
                    r for r in resources 
                    if any(c["configurationName"] == "configuration.origin" and c.get("configurationValue") not in [None, ""] for c in r.get("configurationList", []))
                ]
                all_resources.extend(filtered_resources)
                total_count += len(filtered_resources)
                next_record_key = data.get("nextRecordKey", "")
                
                logger.info(f"Fetched {len(resources)}, kept {len(filtered_resources)}, Total: {total_count}")
                if total_count > 0 and summary_count and total_count > summary_count * 1.1:
                    logger.warning(f"Overcount: {total_count} vs. {summary_count}")
                    break
                
                if not next_record_key or len(resources) == 0:
                    logger.info("Fetch complete")
                    break
            else:
                logger.error(f"Failed: {response.status_code} - {response.text}")
                break
        except Exception as e:
            logger.error(f"Exception: {str(e)}", exc_info=True)
            break

    logger.info(f"Final count: {total_count}")
    return all_resources, total_count
​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​


def filter_tier1_resources(resources: List[Dict], config_key: str, fields: List[str]) -> Tuple[int, pd.DataFrame]:
    logger.info(f"Tier 1 filtering for {config_key}")
    matching_count = 0
    non_matching_resources = []

    for i, resource in enumerate(resources):
        config_list = resource.get("configurationList", [])
        has_config = any(c["configurationName"] == f"configuration.{config_key}" and c.get("configurationValue") not in [None, ""] for c in config_list)
        if has_config:
            matching_count += 1
        else:
            filtered_resource = {field: next((c["configurationValue"] for c in config_list if c["configurationName"] == field), resource.get(field, "N/A")) for field in fields}
            non_matching_resources.append(filtered_resource)
            logger.debug(f"Non-compliant {i}: {filtered_resource}")

    logger.info(f"Tier 1: {matching_count}/{len(resources)}")
    df = pd.DataFrame(non_matching_resources) if non_matching_resources else pd.DataFrame([{"accountResourceId": "No non-compliant resources found"}], columns=fields)
    return matching_count, df

def filter_tier2_resources(resources: List[Dict], config_key: str, config_value: str, fields: List[str]) -> Tuple[int, pd.DataFrame]:
    logger.info(f"Tier 2 filtering for {config_key} = {config_value}")
    matching_count = 0
    non_matching_resources = []

    for i, resource in enumerate(resources):
        config_list = resource.get("configurationList", [])
        value = next((c["configurationValue"] for c in config_list if c["configurationName"] == f"configuration.{config_key}"), None)
        if value == config_value:
            matching_count += 1
        else:
            filtered_resource = {field: next((c["configurationValue"] for c in config_list if c["configurationName"] == field), resource.get(field, "N/A")) for field in fields}
            non_matching_resources.append(filtered_resource)
            logger.debug(f"Non-compliant {i}: {filtered_resource}")

    logger.info(f"Tier 2: {matching_count}/{len(resources)}")
    df = pd.DataFrame(non_matching_resources) if non_matching_resources else pd.DataFrame([{"accountResourceId": "No non-compliant resources found"}], columns=fields)
    return matching_count, df

# load_thresholds and get_compliance_status unchanged
​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​





def main():
    spark = SparkSession.builder.appName("KMSStorageMonitoring").getOrCreate()
    logger.info("Spark session initialized")

    summary_payload = {
        "searchParameters": {
            "resourceType": "AWS::KMS::Key",
            "configurationItems": [{"configurationName": "origin", "configurationValue": "AWS_KMS"}],
            "aggregations": ["resourceType"]
        }
    }
    config_payload = {
        "searchParameters": [{"resourceType": "AWS::KMS::Key"}]
    }

    CONFIG_KEY = "origin"
    CONFIG_VALUE = "AWS_KMS"
    DESIRED_FIELDS = ["accountResourceId", "configuration.origin"]
    TIER1_METRIC_ID = "MNTR-KMS-STORAGE-T1"
    TIER2_METRIC_ID = "MNTR-KMS-STORAGE-T2"

    # Step 1: Summary count
    summary_count = get_summary_count(summary_payload)
    if summary_count is None:
        logger.error("Failed summary count. Exiting.")
        return
    logger.info(f"Summary count: {summary_count}")

    # Step 2: Fetch resources
    all_resources, config_total_count = fetch_all_resources(config_payload, summary_count)
    logger.info(f"Total resources: {config_total_count}")
    if config_total_count < summary_count * 0.9 or config_total_count > summary_count * 1.1:
        logger.warning(f"Mismatch: {config_total_count} vs. {summary_count}")

    # Step 3 & 4: Filter
    tier1_numerator, tier1_df = filter_tier1_resources(all_resources, CONFIG_KEY, DESIRED_FIELDS)
    tier2_numerator, tier2_df = filter_tier2_resources(all_resources, CONFIG_KEY, CONFIG_VALUE, DESIRED_FIELDS)
    print("Tier 1 Non-compliant:", tier1_df)
    print("Tier 2 Non-compliant:", tier2_df)

    # Step 5: Metrics
    thresholds_df = load_thresholds(spark)
    tier1_threshold = thresholds_df[thresholds_df["MONITORING_METRIC_ID"] == TIER1_METRIC_ID].iloc[0]
    tier2_threshold = thresholds_df[thresholds_df["MONITORING_METRIC_ID"] == TIER2_METRIC_ID].iloc[0]
    
    tier1_metric = tier1_numerator / config_total_count if config_total_count > 0 else 0
    tier1_status = get_compliance_status(1 - tier1_metric, tier1_threshold["ALERT_THRESHOLD"], tier1_threshold["WARNING_THRESHOLD"])
    tier2_denominator = tier1_numerator
    tier2_metric = tier2_numerator / tier2_denominator if tier2_denominator > 0 else 0
    tier2_status = get_compliance_status(1 - tier2_metric, tier2_threshold["ALERT_THRESHOLD"], tier2_threshold["WARNING_THRESHOLD"])

    # Step 6: Monitoring DataFrame
    monitoring_df = pd.DataFrame([
        {"DATE": datetime.now().strftime("%Y-%m-%d"), "MONITORING_METRIC_NUMBER": TIER1_METRIC_ID, "MONITORING_METRIC": f"{round(tier1_metric * 100, 2)}%", "COMPLIANCE_STATUS": tier1_status, "NUMERATOR": tier1_numerator, "DENOMINATOR": config_total_count},
        {"DATE": datetime.now().strftime("%Y-%m-%d"), "MONITORING_METRIC_NUMBER": TIER2_METRIC_ID, "MONITORING_METRIC": f"{round(tier2_metric * 100, 2)}%", "COMPLIANCE_STATUS": tier2_status, "NUMERATOR": tier2_numerator, "DENOMINATOR": tier2_denominator}
    ])
    print("Monitoring Metrics:", monitoring_df)

    # Step 7: Log results
    logger.info(f"Results: Summary={summary_count}, Total={config_total_count}, T1={tier1_numerator}, T2={tier2_numerator}")
​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​