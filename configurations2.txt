def fetch_all_resources(payload: Dict, limit: Optional[int] = None, validate_only: bool = False, 
                        timeout: int = 30, max_retries: int = 3) -> Tuple[List[Dict], int]:
    """
    Fetch resources with pagination, timeout, and retry logic.
    
    Args:
        payload: API request payload
        limit: Optional limit on number of resources to fetch
        validate_only: If True, only fetch first page for validation
        timeout: Timeout in seconds for each API request
        max_retries: Maximum number of retry attempts for failed requests
        
    Returns:
        Tuple of (list of resources, total count)
    """
    all_resources = []
    total_count = 0
    next_record_key = ""
    fetch_payload = payload.copy()
    if limit:
        fetch_payload["limit"] = min(limit, 1000)  # API typically limits to 1000 per page
    
    # Get total count from summary-view API
    summary_payload = {
        "searchParameters": payload.get("searchParameters", {}),
        "aggregations": ["resourceType"]
    }
    expected_total = get_summary_count(summary_payload, timeout=timeout)
    if expected_total is None:
        expected_total = limit if limit else 150000  # Fallback to estimate
    
    page_size = fetch_payload.get("limit", 1000)
    if not page_size:  # Ensure page_size is set
        page_size = 1000
        fetch_payload["limit"] = page_size
    
    max_pages = (expected_total // page_size) + 2  # Add buffer for any new resources
    
    logger.info(f"Fetching resources with payload: {json.dumps(fetch_payload, indent=2)}")
    logger.info(f"Max pages set to {max_pages}, timeout {timeout}s, max retries {max_retries}")
    
    page_count = 0
    start_time = datetime.now()
    
    while page_count < max_pages:
        if next_record_key:
            fetch_payload["nextRecordKey"] = next_record_key
        
        # Retry logic for resilience
        for retry in range(max_retries + 1):
            try:
                logger.info(f"Requesting page {page_count + 1}" + (f" (retry {retry})" if retry > 0 else ""))
                response = requests.post(
                    CONFIG_URL, 
                    headers=HEADERS, 
                    data=json.dumps(fetch_payload), 
                    verify=False,
                    timeout=timeout
                )
                
                if response.status_code == 200:
                    data = response.json()
                    # Log a sample of the response structure
                    sample_data = json.dumps({k: v[:1] if isinstance(v, list) and len(v) > 0 else v 
                                             for k, v in data.items()}, indent=2)
                    logger.debug(f"Sample response structure: {sample_data}")
                    
                    resources = data.get("resourceConfigurations", [])
                    # Log structure of first resource and available configuration paths
                    if resources:
                        logger.debug(f"Resource structure: {json.dumps(resources[0], indent=2)}")
                        logger.debug(f"Configuration paths available: {[c['configurationName'] for c in resources[0].get('configurationList', [])]}")
                    
                    all_resources.extend(resources)
                    total_count += len(resources)
                    next_record_key = data.get("nextRecordKey", "")
                    
                    # Calculate and log progress metrics
                    elapsed = (datetime.now() - start_time).total_seconds()
                    rate = total_count / elapsed if elapsed > 0 else 0
                    eta_seconds = (expected_total - total_count) / rate if rate > 0 else 0
                    eta = f"{int(eta_seconds // 3600)}h {int((eta_seconds % 3600) // 60)}m {int(eta_seconds % 60)}s"
                    
                    logger.info(
                        f"Page {page_count + 1}: Fetched {len(resources)} resources, "
                        f"total: {total_count}, rate: {rate:.1f}/sec, ETA: {eta if rate > 0 else 'N/A'}"
                    )
                    
                    page_count += 1
                    # Exit conditions
                    if validate_only or not next_record_key or (limit and total_count >= limit):
                        logger.info("Reached exit condition for pagination")
                        break
                    
                    # Successfully processed this page, break retry loop
                    break
                    
                elif response.status_code == 429:  # Rate limiting
                    wait_time = min(2 ** retry, 60)  # Exponential backoff
                    logger.warning(f"Rate limited (429). Waiting {wait_time}s before retry.")
                    time.sleep(wait_time)
                    if retry == max_retries:
                        logger.error("Max retries reached for rate limiting.")
                        break
                else:
                    logger.error(f"Config API failed: {response.status_code} - {response.text}")
                    if retry == max_retries:
                        break
                    wait_time = min(2 ** retry, 30)
                    logger.info(f"Retrying in {wait_time}s...")
                    time.sleep(wait_time)
                    
            except requests.exceptions.Timeout:
                logger.warning(f"Request timeout after {timeout}s")
                if retry == max_retries:
                    logger.error("Max retries reached after timeouts.")
                    break
                wait_time = min(2 ** retry, 30)
                logger.info(f"Retrying in {wait_time}s...")
                time.sleep(wait_time)
                
            except Exception as e:
                logger.error(f"Exception fetching resources: {str(e)}")
                if retry == max_retries:
                    break
                wait_time = min(2 ** retry, 30)
                logger.info(f"Retrying in {wait_time}s...")
                time.sleep(wait_time)
        
        # If we didn't get a successful response after all retries
        if retry == max_retries:
            logger.error("Failed to fetch page after maximum retries. Stopping pagination.")
            break
            
        # If we've exited the retry loop due to validation or reaching the limit
        if validate_only or not next_record_key or (limit and total_count >= limit):
            break
    
    if page_count >= max_pages and next_record_key:
        logger.warning(f"Max pages ({max_pages}) reached but more data available. Continuing pagination.")
        max_pages = page_count + 1  # Extend max_pages to allow continued fetching
    
    total_time = (datetime.now() - start_time).total_seconds()
    logger.info(f"Fetch complete: {total_count} resources in {page_count} pages, {total_time:.1f} seconds")
    return all_resources, total_count
