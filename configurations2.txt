# --- Replace your existing load_thresholds function with this one ---

# Import List if not already imported at the top
from typing import List 

# Define constants for Snowflake connection if not already defined globally
# SNOWFLAKE_SOURCE_NAME = "net.snowflake.spark.snowflake" 
# SF_OPTIONS = { ... your options ... }
# THRESHOLD_TABLE = "CYBR_DB_COLLAB.LAB_ESRA_TCRD.CYBER_CONTROLS_MONITORING_THRESHOLD" 

def load_thresholds(spark: SparkSession, metric_ids: List[str]) -> pd.DataFrame:
    """Load compliance thresholds from Snowflake for specific metric IDs."""
    
    # Check if metric_ids list is empty
    if not metric_ids:
        logger.warning("No metric IDs provided to load_thresholds. Returning empty DataFrame.")
        return pd.DataFrame()
        
    # Format metric IDs for SQL IN clause to prevent SQL injection issues with simple formatting
    # Ensure metric IDs are strings and properly quoted
    safe_metric_ids = [f"'{str(mid).replace('\'', '')}'" for mid in metric_ids if mid] # Basic quoting and removal of internal quotes
    if not safe_metric_ids:
         logger.warning("No valid metric IDs remaining after validation. Returning empty DataFrame.")
         return pd.DataFrame()
         
    metric_ids_str = ", ".join(safe_metric_ids)
    
    # Construct the dynamic query
    # Use the globally defined THRESHOLD_TABLE constant
    query = f"""
    SELECT MONITORING_METRIC_ID, ALERT_THRESHOLD, WARNING_THRESHOLD 
    FROM {THRESHOLD_TABLE} 
    WHERE MONITORING_METRIC_ID IN ({metric_ids_str})
    """
    logger.info(f"Loading thresholds from Snowflake with query: {query}")
    
    try:
        # Execute the query using Spark Snowflake connector
        thresholds_spark_df = spark.read.format(SNOWFLAKE_SOURCE_NAME) \
            .options(**SF_OPTIONS) \
            .option("query", query) \
            .load()
        
        # Collect results into a Pandas DataFrame for easier use later
        thresholds_pd_df = thresholds_spark_df.toPandas() 
        
        logger.info(f"Threshold data collected from Snowflake. Found {len(thresholds_pd_df)} rows.")
        
        if not thresholds_pd_df.empty:
             # Standardize column names to uppercase for consistency
             thresholds_pd_df.columns = [col.upper() for col in thresholds_pd_df.columns]
             # Check required columns exist
             required_cols = ["MONITORING_METRIC_ID", "ALERT_THRESHOLD", "WARNING_THRESHOLD"]
             if not all(col in thresholds_pd_df.columns for col in required_cols):
                  logger.error(f"Snowflake response missing required columns. Expected: {required_cols}, Got: {list(thresholds_pd_df.columns)}")
                  return pd.DataFrame() # Return empty if columns are missing
                  
             logger.debug(f"Thresholds loaded:\n{thresholds_pd_df.to_string()}")
             return thresholds_pd_df
        else:
             # Query executed but returned no rows for the specified IDs
             logger.warning("No threshold data found in Snowflake for the specified metric IDs.")
             return pd.DataFrame() # Return empty DataFrame
             
    except Exception as e:
        # Log any exception during the Snowflake read operation
        logger.error(f"Failed to load thresholds from Snowflake: {e}", exc_info=True)
        return pd.DataFrame() # Return empty DataFrame on error
