# COMMAND ----------
# MAGIC %md
# MAGIC ## 10. Tier 1 Metrics Calculation
# MAGIC Calculate compliance metrics using a Python-based pipeline after PySpark data loading

# COMMAND ----------
from pyspark.sql.functions import col
import logging
from datetime import datetime, date
import pandas as pd

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

try:
    # Verify date import
    logger.info(f"Verifying date import: {date} is defined, type: {type(date)}")

    # Load Tier 1 thresholds from Snowflake using PySpark
    logger.info("Loading Tier 1 thresholds from Snowflake")
    thresholds_df = spark.read.format(SNOWFLAKE_SOURCE_NAME) \
        .options(**sfOptions) \
        .option("query", tier1_threshold_query) \
        .load()
    
    thresholds_df.show()
    threshold_data = thresholds_df.collect()
    logger.info(f"Threshold data collected: {threshold_data}, type: {type(threshold_data)}")
    
    alert_threshold_raw = threshold_data[0]["ALERT_THRESHOLD"] if threshold_data else None
    warning_threshold_raw = threshold_data[0]["WARNING_THRESHOLD"] if threshold_data else None
    logger.info(f"Alert threshold: {alert_threshold_raw}, type: {type(alert_threshold_raw)}")
    logger.info(f"Warning threshold: {warning_threshold_raw}, type: {type(warning_threshold_raw)}")

    # Load filtered and evaluated roles from PySpark DataFrames
    logger.info("Loading filtered and evaluated roles")
    if not 'df_filtered' in locals() or df_filtered is None:
        df_filtered = spark.table("filtered_machine_roles")
    if not 'df_evaluated_roles' in locals() or df_evaluated_roles is None:
        df_evaluated_roles = spark.table("evaluated_roles")
    
    # Convert to Python lists
    filtered_data = [(row["RESOURCE_ID"], row["AMAZON_RESOURCE_NAME"]) for row in df_filtered.collect()]
    evaluated_data = [row["RESOURCE_NAME"] for row in df_evaluated_roles.collect()]
    logger.info(f"Filtered data count: {len(filtered_data)}, type: {type(filtered_data)}")
    logger.info(f"Evaluated data count: {len(evaluated_data)}, type: {type(evaluated_data)}")

    # Calculate numerator and denominator in Python
    evaluated_set = set(evaluated_data)
    total_set = set(row[1] for row in filtered_data)  # Using AMAZON_RESOURCE_NAME
    evaluated_count = len([arn for arn in total_set if arn in evaluated_set])
    total_count = len(total_set)
    logger.info(f"Evaluated count: {evaluated_count}, type: {type(evaluated_count)}")
    logger.info(f"Total count: {total_count}, type: {type(total_count)}")

    # Perform metric calculation in Python
    def calculate_metrics(alert_val, warning_val, evaluated_cnt, total_cnt):
        """Pure Python function to calculate metrics with corrected status logic."""
        alert = float(alert_val) if alert_val is not None else None
        warning = float(warning_val) if warning_val is not None else None
        evaluated = int(evaluated_cnt)
        total = int(total_cnt)
        
        metric = evaluated / total * 100 if total > 0 else 0.0
        metric = round(metric, 2)  # Python's built-in round
        
        # Corrected status logic
        status = "GREEN"
        if alert is not None and metric <= alert:
            status = "RED"
        elif warning is not None and metric <= warning and metric > alert:
            status = "YELLOW"
        logger.info(f"Calculated metric: {metric}, status: {status} with alert={alert}, warning={warning}")
        return {
            "metric": metric,
            "status": status,
            "numerator": evaluated,
            "denominator": total
        }

    # Run calculations
    results = calculate_metrics(alert_threshold_raw, warning_threshold_raw, evaluated_count, total_count)
    logger.info(f"Calculation results: {results}")

    # Get current date as a Python object
    current_date_value = date.today()
    logger.info(f"Current date: {current_date_value}, type: {type(current_date_value)}")

    # Prepare metrics data as a Python dictionary for pandas DataFrame
    metrics_data = {
        "DATE": [current_date_value],
        "MONITORING_METRIC_NUMBER": ['MNTR-XXXXX-T1'],
        "MONITORING_METRIC": [results["metric"]],
        "COMPLIANCE_STATUS": [results["status"]],
        "NUMERATOR": [results["numerator"]],
        "DENOMINATOR": [results["denominator"]]
    }
    logger.info(f"Metrics data: {metrics_data}")
    logger.info(f"Metrics data types: {[type(x[0]) for x in metrics_data.values()]}")

    # Convert to pandas DataFrame and then to PySpark DataFrame
    pd_df = pd.DataFrame(metrics_data)
    df_result = spark.createDataFrame(pd_df)
    logger.info("DataFrame created from pandas DataFrame")
    df_result.printSchema()
    logger.info("DataFrame content:")
    df_result.show()

    # Store key metrics as global variables
    spark.sql(f"SET tier1_numerator = {results['numerator']}")
    spark.sql(f"SET tier1_denominator = {results['denominator']}")
    spark.sql(f"SET tier1_metric_value = {results['metric']}")
    spark.sql(f"SET tier1_compliance_status = '{results['status']}'")

except Exception as e:
    logger.error(f"ERROR in Tier 1 metrics calculation: {str(e)}")
    raise

# COMMAND ----------
# MAGIC %md
# MAGIC ## Unit Tests for Tier 1 Metrics Calculation

# COMMAND ----------
def test_tier1_metrics_calculation(spark):
    """Unit test for Tier 1 metrics calculation and DataFrame creation."""
    # Mock data
    mock_filtered_data = spark.createDataFrame(
        [("res1", "arn1"), ("res2", "arn2"), ("res3", "arn3")],
        ["RESOURCE_ID", "AMAZON_RESOURCE_NAME"]
    )
    mock_evaluated_data = spark.createDataFrame(
        [("arn1",), ("arn3",)],
        ["RESOURCE_NAME"]
    )
    mock_thresholds = spark.createDataFrame(
        [(100.0, 80.0)],  # Alert: 100.0, Warning: 80.0
        ["ALERT_THRESHOLD", "WARNING_THRESHOLD"]
    )

    # Collect data
    filtered_data = [(row["RESOURCE_ID"], row["AMAZON_RESOURCE_NAME"]) for row in mock_filtered_data.collect()]
    evaluated_data = [row["RESOURCE_NAME"] for row in mock_evaluated_data.collect()]
    threshold_data = mock_thresholds.collect()

    # Calculate metrics
    evaluated_set = set(evaluated_data)
    total_set = set(row[1] for row in filtered_data)
    evaluated_count = len([arn for arn in total_set if arn in evaluated_set])
    total_count = len(total_set)
    alert_threshold = threshold_data[0]["ALERT_THRESHOLD"]
    warning_threshold = threshold_data[0]["WARNING_THRESHOLD"]

    results = calculate_metrics(alert_threshold, warning_threshold, evaluated_count, total_count)
    
    # Prepare metrics data
    metrics_data = {
        "DATE": [date.today()],
        "MONITORING_METRIC_NUMBER": ['MNTR-XXXXX-T1'],
        "MONITORING_METRIC": [results["metric"]],
        "COMPLIANCE_STATUS": [results["status"]],
        "NUMERATOR": [results["numerator"]],
        "DENOMINATOR": [results["denominator"]]
    }

    # Convert to pandas DataFrame and then to PySpark DataFrame
    pd_df = pd.DataFrame(metrics_data)
    df_result = spark.createDataFrame(pd_df)

    # Assertions
    collected_result = df_result.collect()[0]
    assert collected_result["NUMERATOR"] == 2, f"Expected numerator 2, got {collected_result['NUMERATOR']}"
    assert collected_result["DENOMINATOR"] == 3, f"Expected denominator 3, got {collected_result['DENOMINATOR']}"
    assert round(collected_result["MONITORING_METRIC"], 2) == 66.67, f"Expected metric ~66.67%, got {collected_result['MONITORING_METRIC']}"
    assert collected_result["COMPLIANCE_STATUS"] == "RED", f"Expected status RED, got {collected_result['COMPLIANCE_STATUS']}"  # Updated expectation
    logger.info("Unit test for Tier 1 metrics calculation and DataFrame creation passed!")

# Run unit test
test_tier1_metrics_calculation(spark)
​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​