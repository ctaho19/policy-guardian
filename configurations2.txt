 # COMMAND ----------
    # MAGIC %md
    # MAGIC ## 7. Tier 1 Supporting Evidence
    # MAGIC Display details of machine roles that were not evaluated against the control

    try:
        # Define schema for supporting evidence
        evidence_schema = StructType([
            StructField("RESOURCE_ID", StringType(), True),
            StructField("ARN", StringType(), True),
            StructField("ACCOUNT", StringType(), True),
            StructField("BA", StringType(), True),
            StructField("CREATE_DATE", TimestampType(), True),
            StructField("ROLE_TYPE", StringType(), True),
            StructField("NOTES", StringType(), True)
        ])
        
        if numerator < denominator:
            # Filter for unevaluated machine roles
            df_supporting_evidence = df_filtered.filter(col("IS_EVALUATED") == 0) \
                .select(
                    col("RESOURCE_ID"),
                    col("AMAZON_RESOURCE_NAME").alias("ARN"),
                    col("ACCOUNT"),
                    col("BA"),
                    col("CREATE_DATE"),
                    col("ROLE_TYPE"),
                    lit(None).cast(StringType()).alias("NOTES")
                ) \
                .orderBy(["ACCOUNT", "AMAZON_RESOURCE_NAME"])
        else:
            # Create single-row DataFrame with message when all roles are evaluated
            df_supporting_evidence = spark.createDataFrame([
                (None, None, None, None, None, None, "All Roles Evaluated Against Control")
            ], evidence_schema)
        
        # Display results
        log_step("Supporting Evidence DataFrame Created")
        df_supporting_evidence.show(20, truncate=False)
        
    except Exception as e:
        log_step("ERROR in supporting evidence", 
                 f"Failed to generate supporting evidence: {str(e)}")
        raise

